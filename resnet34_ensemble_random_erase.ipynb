{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDceLqL3HZ9p"
   },
   "source": [
    "# Download and install stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "siAmEc3oonfL",
    "outputId": "b39f1a74-e059-45cf-e9c6-afc701328923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 18 13:13:45 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   43C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "a-MMPbIuNMAJ",
    "outputId": "7fface64-df14-4526-9c90-caa4e3ad3b20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-18 13:13:48--  https://sutdapac-my.sharepoint.com/:u:/g/personal/gary_ong_mymail_sutd_edu_sg/EQGuIT9UUFlDv4IVasLW2dIBANJ5TPjK_hJfZ4yZS11LJQ?e=k6chXZ&download=1\n",
      "Resolving sutdapac-my.sharepoint.com (sutdapac-my.sharepoint.com)... 13.107.136.9\n",
      "Connecting to sutdapac-my.sharepoint.com (sutdapac-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /personal/gary_ong_mymail_sutd_edu_sg/Documents/BengaliDataset/split-0.zip?&originalPath=aHR0cHM6Ly9zdXRkYXBhYy1teS5zaGFyZXBvaW50LmNvbS86dTovZy9wZXJzb25hbC9nYXJ5X29uZ19teW1haWxfc3V0ZF9lZHVfc2cvRVFHdUlUOVVVRmxEdjRJVmFzTFcyZElCQU5KNVRQaktfaEpmWjR5WlMxMUxKUT9ydGltZT15ekYtVlpyajEwZw [following]\n",
      "--2020-04-18 13:13:49--  https://sutdapac-my.sharepoint.com/personal/gary_ong_mymail_sutd_edu_sg/Documents/BengaliDataset/split-0.zip?&originalPath=aHR0cHM6Ly9zdXRkYXBhYy1teS5zaGFyZXBvaW50LmNvbS86dTovZy9wZXJzb25hbC9nYXJ5X29uZ19teW1haWxfc3V0ZF9lZHVfc2cvRVFHdUlUOVVVRmxEdjRJVmFzTFcyZElCQU5KNVRQaktfaEpmWjR5WlMxMUxKUT9ydGltZT15ekYtVlpyajEwZw\n",
      "Reusing existing connection to sutdapac-my.sharepoint.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1099653377 (1.0G) [application/x-zip-compressed]\n",
      "Saving to: ‘split-0.zip’\n",
      "\n",
      "split-0.zip         100%[===================>]   1.02G  54.2MB/s    in 24s     \n",
      "\n",
      "2020-04-18 13:14:14 (43.0 MB/s) - ‘split-0.zip’ saved [1099653377/1099653377]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c \"https://sutdapac-my.sharepoint.com/:u:/g/personal/gary_ong_mymail_sutd_edu_sg/EQGuIT9UUFlDv4IVasLW2dIBANJ5TPjK_hJfZ4yZS11LJQ?e=k6chXZ&download=1\" -O split-0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "unYcjx-sNhqL",
    "outputId": "a40eedf4-96b6-4b76-f3b1-c6ea0da44908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-18 13:14:16--  https://sutdapac-my.sharepoint.com/:u:/g/personal/gary_ong_mymail_sutd_edu_sg/EbxFBne-jWFMuP1dYk6H_DgBV5IJLQPt2BYtNW8dv0PNew?e=761f5d&download=1\n",
      "Resolving sutdapac-my.sharepoint.com (sutdapac-my.sharepoint.com)... 13.107.136.9\n",
      "Connecting to sutdapac-my.sharepoint.com (sutdapac-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /personal/gary_ong_mymail_sutd_edu_sg/Documents/BengaliDataset/unseen-val.zip?&originalPath=aHR0cHM6Ly9zdXRkYXBhYy1teS5zaGFyZXBvaW50LmNvbS86dTovZy9wZXJzb25hbC9nYXJ5X29uZ19teW1haWxfc3V0ZF9lZHVfc2cvRWJ4RkJuZS1qV0ZNdVAxZFlrNkhfRGdCVjVJSkxRUHQyQll0Tlc4ZHYwUE5ldz9ydGltZT1FR0FNWnByajEwZw [following]\n",
      "--2020-04-18 13:14:17--  https://sutdapac-my.sharepoint.com/personal/gary_ong_mymail_sutd_edu_sg/Documents/BengaliDataset/unseen-val.zip?&originalPath=aHR0cHM6Ly9zdXRkYXBhYy1teS5zaGFyZXBvaW50LmNvbS86dTovZy9wZXJzb25hbC9nYXJ5X29uZ19teW1haWxfc3V0ZF9lZHVfc2cvRWJ4RkJuZS1qV0ZNdVAxZFlrNkhfRGdCVjVJSkxRUHQyQll0Tlc4ZHYwUE5ldz9ydGltZT1FR0FNWnByajEwZw\n",
      "Reusing existing connection to sutdapac-my.sharepoint.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42566918 (41M) [application/x-zip-compressed]\n",
      "Saving to: ‘unseen-val.zip’\n",
      "\n",
      "unseen-val.zip      100%[===================>]  40.59M  14.4MB/s    in 2.8s    \n",
      "\n",
      "2020-04-18 13:14:20 (14.4 MB/s) - ‘unseen-val.zip’ saved [42566918/42566918]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c \"https://sutdapac-my.sharepoint.com/:u:/g/personal/gary_ong_mymail_sutd_edu_sg/EbxFBne-jWFMuP1dYk6H_DgBV5IJLQPt2BYtNW8dv0PNew?e=761f5d&download=1\" -O unseen-val.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "b4NVJMYqRr8c",
    "outputId": "94c3fc8e-a4ba-4aeb-8d17-2a815f15ebe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  split-0.zip\n",
      "  inflating: train-0.csv             \n",
      "  inflating: train-0.npy             \n",
      "  inflating: val-0.csv               \n",
      "  inflating: val-0.npy               \n"
     ]
    }
   ],
   "source": [
    "!unzip split-0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WihCkaRaBI60",
    "outputId": "d720987d-3075-4d8c-b7fc-cdbc377db147"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  unseen-val.zip\n",
      "  inflating: unseen-val.csv          \n",
      "  inflating: unseen-val.npy          \n"
     ]
    }
   ],
   "source": [
    "!unzip unseen-val.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WgpDvjg4BPZu",
    "outputId": "d9562aa3-0a5c-461c-9061-ed1e100cb569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  train-0.csv  unseen-val.csv  unseen-val.zip  val-0.npy\n",
      "split-0.zip  train-0.npy  unseen-val.npy  val-0.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "NHTVSya3SCne",
    "outputId": "664a6df9-a558-435a-ecd0-ac64e09d6520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/albu/albumentations\n",
      "  Cloning https://github.com/albu/albumentations to /tmp/pip-req-build-dk7nlmxu\n",
      "  Running command git clone -q https://github.com/albu/albumentations /tmp/pip-req-build-dk7nlmxu\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.4.1)\n",
      "Collecting imgaug<0.2.7,>=0.2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
      "\u001b[K     |████████████████████████████████| 634kB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (4.1.2.30)\n",
      "Requirement already satisfied, skipping upgrade: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.16.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (7.0.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (4.4.2)\n",
      "Building wheels for collected packages: albumentations, imgaug\n",
      "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for albumentations: filename=albumentations-0.4.5-cp36-none-any.whl size=65099 sha256=04d8550842b1c513ddd9eac7d59b3f8f8eef939e784a6adaf190080e347b18ba\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-u0crjqba/wheels/45/8b/e4/2837bbcf517d00732b8e394f8646f22b8723ac00993230188b\n",
      "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=14706aa29fe16fc9f0bc4249088fdb5880b5681ec76beeb44ee7c9ffd571fd06\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-u0crjqba/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
      "Successfully built albumentations imgaug\n",
      "Installing collected packages: imgaug, albumentations\n",
      "  Found existing installation: imgaug 0.2.9\n",
      "    Uninstalling imgaug-0.2.9:\n",
      "      Successfully uninstalled imgaug-0.2.9\n",
      "  Found existing installation: albumentations 0.1.12\n",
      "    Uninstalling albumentations-0.1.12:\n",
      "      Successfully uninstalled albumentations-0.1.12\n",
      "Successfully installed albumentations-0.4.5 imgaug-0.2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/albu/albumentations --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0bLantMHwCV"
   },
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UaHtOHNYNqHR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "class BengaliDataset2(Dataset):\n",
    "    def __init__(self,npy_file,label_csv,aug=None,norm=None):\n",
    "        self.npy_file = np.load(npy_file)\n",
    "        self.norm = norm\n",
    "        df = pd.read_csv(label_csv)\n",
    "        # for faster access i think\n",
    "        self.grapheme_root = df[\"grapheme_root\"].values\n",
    "        self.vowel_diacritic = df[\"vowel_diacritic\"].values\n",
    "        self.consonant_diacritic = df[\"consonant_diacritic\"].values\n",
    "\n",
    "        self.aug = aug\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_arr = self.npy_file[index]\n",
    "        # only do this on training\n",
    "        #use albumentations library\n",
    "        if self.aug != None:\n",
    "            image_arr = self.aug(image=image_arr)[\"image\"]\n",
    "\n",
    "        image_arr = (image_arr/255).astype(np.float32)\n",
    "        image_arr = torch.from_numpy(image_arr)\n",
    "\n",
    "        if self.norm != None:\n",
    "            mean = self.norm['mean']\n",
    "            std = self.norm['std']\n",
    "            image_arr = (image_arr -  mean)/std\n",
    "\n",
    "        grapheme_root = torch.Tensor([self.grapheme_root[index]]).long()\n",
    "        vowel_diacritic = torch.Tensor([self.vowel_diacritic[index]]).long()\n",
    "        consonant_diacritic = torch.Tensor([self.consonant_diacritic[index]]).long()\n",
    "        \n",
    "        return {\"image\":image_arr.unsqueeze(0).repeat(3, 1, 1),\"grapheme_root\":grapheme_root,\"vowel_diacritic\":vowel_diacritic,\"consonant_diacritic\":consonant_diacritic}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.npy_file.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6fSyNFnnH6Sr"
   },
   "source": [
    "# Augmentations\n",
    "You can visualize some of the augmentations here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1-qal9-GSX54R3Z0ZbZKGfS0b4k8FS1ji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6zZuGQeRZ1r"
   },
   "outputs": [],
   "source": [
    "import albumentations\n",
    "\n",
    "mean = 13.4/255\n",
    "std = 40.8/255\n",
    "\n",
    "# shift_scale_rotate = A.augmentations.transforms.ShiftScaleRotate(p=0.75,scale_limit=0.4,rotate_limit=30)\n",
    "# brightness = A.augmentations.transforms.RandomBrightness(p=0.5)\n",
    "# grid_distortion = A.augmentations.transforms.GridDistortion(p=0.5,distort_limit=0.4)\n",
    "# blur = A.augmentations.transforms.Blur(p=0.2)\n",
    "# opticalDist = A.augmentations.transforms.OpticalDistortion(p=0.5)\n",
    "# elasticTransform = A.augmentations.transforms.ElasticTransform(p=0.5,alpha_affine=10)\n",
    "# downScale = A.augmentations.transforms.Downscale(p=0.5,scale_min=0.3,scale_max=0.5)\n",
    "# cutOut = A.augmentations.transforms.Cutout(p=1,num_holes=1,max_h_size=64,max_w_size=64)\n",
    "# gd = A.augmentations.transforms.GridDropout(unit_size_min=20,unit_size_max=100,p=0.5,random_offset=True)\n",
    "# gd2 = A.augmentations.transforms.GridDropout(unit_size_min=20,unit_size_max=100,p=0.75,fill_value=255,random_offset=True)\n",
    "# rgs = A.augmentations.transforms.RandomGridShuffle(p=1,grid=(2,2))\n",
    "# aug_list = [A.core.composition.OneOf([gd])]\n",
    "# augment = A.core.composition.Compose(aug_list,p=1)\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from typing import Tuple, List, Dict\n",
    "class ImageTransformer:\n",
    "    \"\"\"\n",
    "    DataAugmentor for Image Classification.\n",
    "    Args:\n",
    "        data_augmentations: List of tuple(method: str, params :dict), each elems pass to albumentations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_augmentations: List[Tuple[str, Dict]]):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        augmentations_list = [\n",
    "            self._get_augmentation(aug_name)(**params)\n",
    "            for aug_name, params in data_augmentations]\n",
    "        self.data_aug = albumentations.Compose(augmentations_list)\n",
    "    \n",
    "    def __call__(self,image):\n",
    "        return self.data_aug(image=image)\n",
    "    \n",
    "    def __call2__(self, pair: Tuple[np.ndarray]) -> Tuple[np.ndarray]:\n",
    "        \"\"\"Forward\"\"\"\n",
    "        img_arr, label = pair\n",
    "        return self.data_aug(image=img_arr)[\"image\"], label\n",
    "\n",
    "    def _get_augmentation(self, aug_name: str) -> ImageOnlyTransform:\n",
    "        \"\"\"Get augmentations from albumentations\"\"\"\n",
    "        if hasattr(albumentations, aug_name):\n",
    "            return getattr(albumentations, aug_name)\n",
    "        else:\n",
    "            return eval(aug_name)\n",
    "        \n",
    "class RandomErasing(ImageOnlyTransform):\n",
    "    \"\"\"Class of RandomErase for Albumentations.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, s: Tuple[float]=(0.02, 0.4), r: Tuple[float]=(0.3, 2.7),\n",
    "        mask_value_min: int=0, mask_value_max: int=255,\n",
    "        always_apply: bool=False, p: float=1.0\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__(always_apply, p)\n",
    "        self.s = s\n",
    "        self.r = r\n",
    "        self.mask_value_min = mask_value_min\n",
    "        self.mask_value_max = mask_value_max\n",
    "\n",
    "    def apply(self, image: np.ndarray, **params):\n",
    "        \"\"\"\n",
    "        Apply transform.\n",
    "        Note: Input image shape is (Height, Width, Channel).\n",
    "        \"\"\"\n",
    "        image_copy = np.copy(image)\n",
    "\n",
    "        # # decide mask value randomly\n",
    "        mask_value = np.random.randint(self.mask_value_min, self.mask_value_max + 1)\n",
    "\n",
    "        h, w = image.shape\n",
    "        # # decide num of pixcels for mask.\n",
    "        mask_area_pixel = np.random.randint(h * w * self.s[0], h * w * self.s[1])\n",
    "\n",
    "        # # decide aspect ratio for mask.\n",
    "        mask_aspect_ratio = np.random.rand() * self.r[1] + self.r[0]\n",
    "\n",
    "        # # decide mask hight and width\n",
    "        mask_height = int(np.sqrt(mask_area_pixel / mask_aspect_ratio))\n",
    "        if mask_height > h - 1:\n",
    "            mask_height = h - 1\n",
    "        mask_width = int(mask_aspect_ratio * mask_height)\n",
    "        if mask_width > w - 1:\n",
    "            mask_width = w - 1\n",
    "\n",
    "        # # decide position of mask.\n",
    "        top = np.random.randint(0, h - mask_height)\n",
    "        left = np.random.randint(0, w - mask_width)\n",
    "        bottom = top + mask_height\n",
    "        right = left + mask_width\n",
    "        image_copy[top:bottom, left:right].fill(mask_value)\n",
    "\n",
    "        return image_copy\n",
    "    \n",
    "augment = ImageTransformer([('RandomErasing',{'p':0.5})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F72wJ7V5FF0W"
   },
   "outputs": [],
   "source": [
    "train_data = BengaliDataset2(\"train-0.npy\",\"train-0.csv\",aug =augment,norm={'mean':mean,'std':std})\n",
    "val_data = BengaliDataset2(\"val-0.npy\",\"val-0.csv\",norm={'mean':mean,'std':std})\n",
    "unseen_val = BengaliDataset2(\"unseen-val.npy\",\"unseen-val.csv\",norm={'mean':mean,'std':std})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1c4zrXnDJNOL"
   },
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmJURapYS0k-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import recall_score,confusion_matrix,ConfusionMatrixDisplay,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWvUNbrrJjLO"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, device, dataloaders, scheduler=None, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    dataset_sizes = {'train': len(dataloaders['train'].dataset),'val': len(dataloaders['val'].dataset),'unseen':len(dataloaders['unseen'].dataset)}\n",
    "\n",
    "    train_acc_list = []; train_loss_list= []; val_acc_list = []; val_loss_list = []; unseen_acc_list = []; unseen_loss_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val','unseen']:\n",
    "            \n",
    "            #used for calculating recall per epoch\n",
    "            grapheme_output = []\n",
    "            vowel_output = []\n",
    "            consonant_output = []\n",
    "            grapheme_label = []\n",
    "            vowel_label = []\n",
    "            consonant_label = []\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            grapheme_corrects = 0\n",
    "            vowel_corrects = 0\n",
    "            consonant_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i,data in enumerate(dataloaders[phase]):\n",
    "\n",
    "                inputs = data['image']\n",
    "                grapheme_root_label = data['grapheme_root']\n",
    "                vowel_diacritic_label = data['vowel_diacritic']\n",
    "                consonant_diacritic_label = data['consonant_diacritic']\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                grapheme_root_label =  grapheme_root_label.to(device)\n",
    "                vowel_diacritic_label = vowel_diacritic_label.to(device)\n",
    "                consonant_diacritic_label =  consonant_diacritic_label.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    g,v,c = model(inputs)\n",
    "                    \n",
    "                    grapheme_preds = g.argmax(dim=1)\n",
    "                    vowel_preds = v.argmax(dim=1) \n",
    "                    consonant_preds = c.argmax(dim=1)\n",
    "\n",
    "                    loss = criterion(g,v,c, grapheme_root_label.squeeze(1),vowel_diacritic_label.squeeze(1),consonant_diacritic_label.squeeze(1))\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                  \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #For accuracy\n",
    "                grapheme_corrects += torch.sum(grapheme_preds == grapheme_root_label.data.squeeze(1))\n",
    "                vowel_corrects += torch.sum(vowel_preds == vowel_diacritic_label.data.squeeze(1))\n",
    "                consonant_corrects += torch.sum(consonant_preds== consonant_diacritic_label.data.squeeze(1))\n",
    "                if phase == 'val' or phase == 'unseen':\n",
    "                  #only do this for val and unseen because transfering to cpu is costly\n",
    "                  grapheme_output.append(grapheme_preds.cpu())\n",
    "                  grapheme_label.append(grapheme_root_label.data.squeeze(1).cpu())\n",
    "                  vowel_output.append(vowel_preds.cpu())\n",
    "                  vowel_label.append(vowel_diacritic_label.data.squeeze(1).cpu())\n",
    "                  consonant_output.append(consonant_preds.cpu())\n",
    "                  consonant_label.append(consonant_diacritic_label.data.squeeze(1).cpu())\n",
    "\n",
    "                if phase == 'train':\n",
    "                  scheduler.step(epoch+i/dataset_sizes['train'])\n",
    "            if phase == 'val' or phase == 'unseen':\n",
    "              grapheme_final_output = torch.cat(grapheme_output)    \n",
    "              grapheme_final_label =  torch.cat(grapheme_label)\n",
    "              \n",
    "              vowel_final_output = torch.cat(vowel_output)    \n",
    "              vowel_final_label =  torch.cat(vowel_label)\n",
    "              \n",
    "              consonant_final_output = torch.cat(consonant_output)    \n",
    "              consonant_final_label =  torch.cat(consonant_label)\n",
    "\n",
    "              grapheme_recall = recall_score(grapheme_final_output,grapheme_final_label,average='macro')\n",
    "              vowel_recall = recall_score(vowel_final_output,vowel_final_label,average='macro')\n",
    "              consonant_recall = recall_score(consonant_final_output,consonant_final_label,average='macro')\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            running_corrects = 0.5*grapheme_corrects.double() + 0.25*vowel_corrects.double() + 0.25*consonant_corrects.double()\n",
    "\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            \n",
    "          \n",
    "            if phase == \"train\":\n",
    "                # Note this are running values (calculated per batch) rather than actual values at the end of each epoch\n",
    "                # Decreases training time\n",
    "                # Not accurate especially at first few epochs\n",
    "                train_acc_list.append(epoch_acc)\n",
    "                train_loss_list.append(epoch_loss)\n",
    "            elif phase == \"val\":\n",
    "                val_acc_list.append(epoch_acc)\n",
    "                val_loss_list.append(epoch_loss)\n",
    "            elif phase == \"unseen\":\n",
    "                unseen_acc_list.append(epoch_acc)\n",
    "                unseen_loss_list.append(epoch_loss)\n",
    "          \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            if phase == 'val' or phase == 'unseen':\n",
    "              total_recall = 0.5*grapheme_recall+0.25*vowel_recall+0.25*consonant_recall\n",
    "              print('Grapheme recall: {:.4f} Vowel recall: {:.4f} Consonant recall: {:.4f} Total Recall:{:.4f}'.\\\n",
    "                    format(grapheme_recall,vowel_recall,consonant_recall,total_recall))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and total_recall > best_recall:\n",
    "                best_recall = total_recall\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if epoch==34 or epoch==69 or epoch==104:\n",
    "                torch.save(model.state_dict(), \"model_epoch\"+str(epoch)+\".pt\")\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"time per epoch:{end-start}s\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val recall: {:4f}'.format(best_recall))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    plots = (train_acc_list,train_loss_list,val_acc_list,val_loss_list,unseen_acc_list,unseen_loss_list)\n",
    "\n",
    "    return model, plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6AhzWBeJ95M"
   },
   "source": [
    "# Loss function and evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyPyPwDXJ0D7"
   },
   "outputs": [],
   "source": [
    "def loss(grapheme_root_output,vowel_diacritic_output,consonant_diacritic_output,grapheme_root_label,vowel_diacritic_label,consonant_diacritic_label):\n",
    "    gloss = nn.CrossEntropyLoss()(grapheme_root_output,grapheme_root_label)\n",
    "    vloss = nn.CrossEntropyLoss()(vowel_diacritic_output,vowel_diacritic_label)\n",
    "    closs = nn.CrossEntropyLoss()(consonant_diacritic_output,consonant_diacritic_label)\n",
    "\n",
    "    return 0.5*gloss + 0.25*vloss + 0.25*closs\n",
    "\n",
    "def evaluate_test(model,criterion,dataloader,device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    grapheme_corrects = 0.0\n",
    "    vowel_corrects = 0.0\n",
    "    consonant_corrects = 0.0\n",
    "    \n",
    "    grapheme_output = []\n",
    "    vowel_output = []\n",
    "    consonant_output = []\n",
    "\n",
    "    grapheme_label = []\n",
    "    vowel_label = []\n",
    "    consonant_label = []\n",
    "\n",
    "\n",
    "    for data in dataloader:\n",
    "\n",
    "        inputs = data['image']\n",
    "\n",
    "        grapheme_root_label = data['grapheme_root']\n",
    "        vowel_diacritic_label = data['vowel_diacritic']\n",
    "        consonant_diacritic_label = data['consonant_diacritic']\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        grapheme_root_label =  grapheme_root_label.to(device)\n",
    "        vowel_diacritic_label = vowel_diacritic_label.to(device)\n",
    "        consonant_diacritic_label =  consonant_diacritic_label.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            g,v,c = model(inputs)\n",
    "\n",
    "            loss = criterion(g,v,c, grapheme_root_label.squeeze(1),vowel_diacritic_label.squeeze(1),consonant_diacritic_label.squeeze(1))\n",
    "            grapheme_preds = g.argmax(dim=1)\n",
    "            vowel_preds = v.argmax(dim=1)\n",
    "            consonant_preds = c.argmax(dim=1)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "\n",
    "        grapheme_corrects += torch.sum(grapheme_preds == grapheme_root_label.data.squeeze(1))\n",
    "        vowel_corrects += torch.sum(vowel_preds == vowel_diacritic_label.data.squeeze(1))\n",
    "        consonant_corrects += torch.sum(consonant_preds== consonant_diacritic_label.data.squeeze(1))\n",
    "        \n",
    "\n",
    "        grapheme_output.append(grapheme_preds.cpu())\n",
    "        grapheme_label.append(grapheme_root_label.data.squeeze(1).cpu())\n",
    "        vowel_output.append(vowel_preds.cpu())\n",
    "        vowel_label.append(vowel_diacritic_label.data.squeeze(1).cpu())\n",
    "        consonant_output.append(consonant_preds.cpu())\n",
    "        consonant_label.append(consonant_diacritic_label.data.squeeze(1).cpu())\n",
    "\n",
    "    grapheme_final_output = torch.cat(grapheme_output)    \n",
    "    grapheme_final_label =  torch.cat(grapheme_label)\n",
    "    \n",
    "    vowel_final_output = torch.cat(vowel_output)    \n",
    "    vowel_final_label =  torch.cat(vowel_label)\n",
    "    \n",
    "    consonant_final_output = torch.cat(consonant_output)    \n",
    "    consonant_final_label =  torch.cat(consonant_label)\n",
    "  \n",
    "\n",
    "    grapheme_recall = recall_score(grapheme_final_output,grapheme_final_label,average='macro')\n",
    "    vowel_recall = recall_score(vowel_final_output,vowel_final_label,average='macro')\n",
    "    consonant_recall = recall_score(consonant_final_output,consonant_final_label,average='macro')\n",
    "\n",
    "    print(\"grapheme recall:\",grapheme_recall)\n",
    "    print(\"vowel_recall:\",vowel_recall)\n",
    "    print(\"consonant_recall:\",consonant_recall)\n",
    "\n",
    "    print(\"final recall:\",0.5*grapheme_recall+0.25*vowel_recall+0.25*consonant_recall)\n",
    "\n",
    "    # print(classification_report(grapheme_final_label,grapheme_final_output))\n",
    "    # fig, axs = plt.subplots()\n",
    "    # fig.set_figheight(15)\n",
    "    # fig.set_figwidth(15)\n",
    "    # cm_vowel = confusion_matrix(grapheme_final_label,grapheme_final_output,normalize='true')\n",
    "    # cm = ConfusionMatrixDisplay(cm_vowel,[x for x in range(168)])\n",
    "    # cm.plot(ax=axs)\n",
    "\n",
    "\n",
    "    loss = running_loss / len(dataloader.dataset)\n",
    "\n",
    "    running_corrects = 0.5*grapheme_corrects.double() + 0.25*vowel_corrects.double() + 0.25*consonant_corrects.double()\n",
    "\n",
    "    # epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "    acc = running_corrects / len(dataloader.dataset)\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        \"Final Test Accuracy\", loss, acc))\n",
    "    return grapheme_final_output,grapheme_final_label,vowel_final_output,vowel_final_label,consonant_final_output,consonant_final_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGHICZixJv0t"
   },
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRfFq4JSJubz"
   },
   "outputs": [],
   "source": [
    "def plot_model_metrics(plots,name):\n",
    "    train_acc_list,train_loss_list,val_acc_list,val_loss_list,test_acc_list,test_loss_list = plots\n",
    "    plot(train_acc_list,val_acc_list,test_acc_list,\"accuracy\",name)\n",
    "    plot(train_loss_list,val_loss_list,test_loss_list,\"loss\",name)\n",
    "\n",
    "\n",
    "def plot(train,val,test,metric,name):\n",
    "    plt.title(name)\n",
    "    plt.plot(train,label=\"train {}\".format(metric))\n",
    "    plt.plot(val,label=\"val {}\".format(metric))\n",
    "    plt.plot(test,label=\"test {}\".format(metric))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"{}-{}\".format(name,metric))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnTQ8eYDKpIn"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsD9uUvnKsIq"
   },
   "outputs": [],
   "source": [
    "# Easier to split stuff up and backpropagate\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    model = models.resnet34(pretrained=True)\n",
    "    self.model = nn.Sequential(*list(model.children())[:-1])#chop off last layer\n",
    "    self.fc_g = nn.Sequential(nn.Linear(512,200), nn.ReLU(), nn.Dropout(p=0.2), nn.Linear(200,168))\n",
    "    self.fc_v = nn.Sequential(nn.Linear(512,200), nn.ReLU(), nn.Dropout(p=0.2), nn.Linear(200,11))\n",
    "    self.fc_c = nn.Sequential(nn.Linear(512,200), nn.ReLU(), nn.Dropout(p=0.2), nn.Linear(200,7))\n",
    "  def forward(self,x):\n",
    "    x = self.model(x)\n",
    "    # print(x.shape)\n",
    "    x = torch.flatten(x,1)\n",
    "    g = self.fc_g(x)\n",
    "    v = self.fc_v(x)\n",
    "    c = self.fc_c(x)\n",
    "    return g,v,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1efded5d14ea4b1f9e789e6916c5ef83",
      "e1bc6a4df460400891cec8fbb840e9ab",
      "2bfcd7f7cffb4acfaef3099e747c44a4",
      "5ce852c0010843f7bf70ae915d9acbb8",
      "440e10a4689346d4a68a02e67abd0bd5",
      "b3e1f27f82b54742b7b5e5502be83328",
      "c98d5053c2ed44a5b77fca9b11a44f8d",
      "67e0308c7c0b4c349882b37daaac2f4f"
     ]
    },
    "colab_type": "code",
    "id": "ANlkaYkwcWTw",
    "outputId": "9f433c28-1de8-419f-9629-8400504fd631"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efded5d14ea4b1f9e789e6916c5ef83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87306240), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_g): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=500, out_features=168, bias=True)\n",
       "  )\n",
       "  (fc_v): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=500, out_features=11, bias=True)\n",
       "  )\n",
       "  (fc_c): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=500, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vp1uYB7FKFXQ"
   },
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zrr1IfwTVGSi"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=128, num_workers=4,shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=128, num_workers=4)\n",
    "unseen_val_loader = DataLoader(unseen_val, batch_size=128, num_workers=4)\n",
    "\n",
    "dataloaders = {'train': train_loader,'val': val_loader,'unseen':unseen_val_loader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nBsCIHZroSEq",
    "outputId": "f37365fe-6f02-482c-f0b1-6b79d02d6d1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/105\n",
      "----------\n",
      "train Loss: 1.1513 Acc: 0.6970\n",
      "val Loss: 0.3493 Acc: 0.8983\n",
      "Grapheme recall: 0.8645 Vowel recall: 0.9417 Consonant recall: 0.8954 Total Recall:0.8915\n",
      "unseen Loss: 0.5750 Acc: 0.8381\n",
      "Grapheme recall: 0.2826 Vowel recall: 0.7711 Consonant recall: 0.7753 Total Recall:0.5279\n",
      "time per epoch:222.21800589561462s\n",
      "Epoch 2/105\n",
      "----------\n",
      "train Loss: 0.6801 Acc: 0.8130\n",
      "val Loss: 0.2261 Acc: 0.9348\n",
      "Grapheme recall: 0.9002 Vowel recall: 0.9667 Consonant recall: 0.9730 Total Recall:0.9350\n",
      "unseen Loss: 0.4942 Acc: 0.8676\n",
      "Grapheme recall: 0.2825 Vowel recall: 0.7855 Consonant recall: 0.8104 Total Recall:0.5402\n",
      "time per epoch:222.07878756523132s\n",
      "Epoch 3/105\n",
      "----------\n",
      "train Loss: 0.5811 Acc: 0.8398\n",
      "val Loss: 0.1814 Acc: 0.9492\n",
      "Grapheme recall: 0.9179 Vowel recall: 0.9804 Consonant recall: 0.9777 Total Recall:0.9485\n",
      "unseen Loss: 0.4407 Acc: 0.8821\n",
      "Grapheme recall: 0.2729 Vowel recall: 0.7986 Consonant recall: 0.8182 Total Recall:0.5406\n",
      "time per epoch:222.08642673492432s\n",
      "Epoch 4/105\n",
      "----------\n",
      "train Loss: 0.5250 Acc: 0.8541\n",
      "val Loss: 0.1589 Acc: 0.9557\n",
      "Grapheme recall: 0.9302 Vowel recall: 0.9791 Consonant recall: 0.9806 Total Recall:0.9550\n",
      "unseen Loss: 0.4918 Acc: 0.8662\n",
      "Grapheme recall: 0.2717 Vowel recall: 0.7768 Consonant recall: 0.8224 Total Recall:0.5357\n",
      "time per epoch:222.23281240463257s\n",
      "Epoch 5/105\n",
      "----------\n",
      "train Loss: 0.4815 Acc: 0.8654\n",
      "val Loss: 0.1418 Acc: 0.9602\n",
      "Grapheme recall: 0.9394 Vowel recall: 0.9739 Consonant recall: 0.9782 Total Recall:0.9577\n",
      "unseen Loss: 0.5297 Acc: 0.8611\n",
      "Grapheme recall: 0.2761 Vowel recall: 0.8658 Consonant recall: 0.8013 Total Recall:0.5549\n",
      "time per epoch:222.2381236553192s\n",
      "Epoch 6/105\n",
      "----------\n",
      "train Loss: 0.4571 Acc: 0.8716\n",
      "val Loss: 0.1402 Acc: 0.9606\n",
      "Grapheme recall: 0.9403 Vowel recall: 0.9801 Consonant recall: 0.9847 Total Recall:0.9614\n",
      "unseen Loss: 0.4956 Acc: 0.8586\n",
      "Grapheme recall: 0.2682 Vowel recall: 0.7732 Consonant recall: 0.8118 Total Recall:0.5303\n",
      "time per epoch:222.39696598052979s\n",
      "Epoch 7/105\n",
      "----------\n",
      "train Loss: 0.4276 Acc: 0.8792\n",
      "val Loss: 0.1383 Acc: 0.9631\n",
      "Grapheme recall: 0.9421 Vowel recall: 0.9798 Consonant recall: 0.9753 Total Recall:0.9598\n",
      "unseen Loss: 0.5765 Acc: 0.8631\n",
      "Grapheme recall: 0.2771 Vowel recall: 0.7933 Consonant recall: 0.9427 Total Recall:0.5726\n",
      "time per epoch:222.047110080719s\n",
      "Epoch 8/105\n",
      "----------\n",
      "train Loss: 0.4077 Acc: 0.8847\n",
      "val Loss: 0.1273 Acc: 0.9656\n",
      "Grapheme recall: 0.9495 Vowel recall: 0.9840 Consonant recall: 0.9822 Total Recall:0.9663\n",
      "unseen Loss: 0.6098 Acc: 0.8475\n",
      "Grapheme recall: 0.2740 Vowel recall: 0.7932 Consonant recall: 0.9420 Total Recall:0.5708\n",
      "time per epoch:222.36644220352173s\n",
      "Epoch 9/105\n",
      "----------\n",
      "train Loss: 0.3941 Acc: 0.8881\n",
      "val Loss: 0.1250 Acc: 0.9675\n",
      "Grapheme recall: 0.9482 Vowel recall: 0.9822 Consonant recall: 0.9808 Total Recall:0.9648\n",
      "unseen Loss: 0.5103 Acc: 0.8762\n",
      "Grapheme recall: 0.2837 Vowel recall: 0.7923 Consonant recall: 0.9550 Total Recall:0.5787\n",
      "time per epoch:222.07750487327576s\n",
      "Epoch 10/105\n",
      "----------\n",
      "train Loss: 0.3788 Acc: 0.8918\n",
      "val Loss: 0.1227 Acc: 0.9678\n",
      "Grapheme recall: 0.9511 Vowel recall: 0.9824 Consonant recall: 0.9816 Total Recall:0.9666\n",
      "unseen Loss: 0.7071 Acc: 0.8384\n",
      "Grapheme recall: 0.2644 Vowel recall: 0.7947 Consonant recall: 0.7918 Total Recall:0.5288\n",
      "time per epoch:222.47497129440308s\n",
      "Epoch 11/105\n",
      "----------\n",
      "train Loss: 0.3647 Acc: 0.8963\n",
      "val Loss: 0.1209 Acc: 0.9684\n",
      "Grapheme recall: 0.9542 Vowel recall: 0.9777 Consonant recall: 0.9835 Total Recall:0.9674\n",
      "unseen Loss: 0.6065 Acc: 0.8553\n",
      "Grapheme recall: 0.2842 Vowel recall: 0.7811 Consonant recall: 0.9405 Total Recall:0.5725\n",
      "time per epoch:221.89446425437927s\n",
      "Epoch 12/105\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0f5b68bcf9cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m model,plots = train_model(model, criterion, optimizer,\n\u001b[0;32m----> 9\u001b[0;31m             device, dataloaders,scheduler=new_scheduler, num_epochs=105)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-3febca5f65c6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, device, dataloaders, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0;31m#For accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mgrapheme_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrapheme_preds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgrapheme_root_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = loss\n",
    "optimizer = optim.SGD(model.parameters(),lr=1.5e-02, momentum=0.9, weight_decay=1e-04, nesterov=True)\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=3,factor=0.3,verbose=True)\n",
    "\n",
    "new_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=35, T_mult=1, eta_min=0, last_epoch=-1)\n",
    "\n",
    "\n",
    "model,plots = train_model(model, criterion, optimizer,\n",
    "            device, dataloaders,scheduler=new_scheduler, num_epochs=105)\n",
    "\n",
    "\n",
    "# plot_model_metrics(plots,\"graph\")\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PdzNhxqp8pqq"
   },
   "outputs": [],
   "source": [
    " grapheme_final_output,grapheme_final_label,vowel_final_output,vowel_final_label,consonant_final_output,consonant_final_label = evaluate_test(model,criterion,val_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxeuRPqoXJH7"
   },
   "outputs": [],
   "source": [
    "grapheme_final_output,grapheme_final_label,vowel_final_output,vowel_final_label,consonant_final_output,consonant_final_label = evaluate_test(model,criterion,unseen_val_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmrpocq8HVJc"
   },
   "outputs": [],
   "source": [
    "#print(classification_report(grapheme_final_label,grapheme_final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYrzE8plp6bi"
   },
   "outputs": [],
   "source": [
    "plot_model_metrics(plots,\"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-ydXuT7qu--"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCj2YcJmAVvD"
   },
   "outputs": [],
   "source": [
    "!cp graph-accuracy.png ./drive/'My Drive'/accuracy-graph.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVlGoR9cAdMJ"
   },
   "outputs": [],
   "source": [
    "!cp graph-loss.png ./drive/'My Drive'/loss-graph.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1Er1cE0Ae5R"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"mynet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hV70rb044OUV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "resnet-random-erase.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1efded5d14ea4b1f9e789e6916c5ef83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bfcd7f7cffb4acfaef3099e747c44a4",
       "IPY_MODEL_5ce852c0010843f7bf70ae915d9acbb8"
      ],
      "layout": "IPY_MODEL_e1bc6a4df460400891cec8fbb840e9ab"
     }
    },
    "2bfcd7f7cffb4acfaef3099e747c44a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3e1f27f82b54742b7b5e5502be83328",
      "max": 87306240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_440e10a4689346d4a68a02e67abd0bd5",
      "value": 87306240
     }
    },
    "440e10a4689346d4a68a02e67abd0bd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5ce852c0010843f7bf70ae915d9acbb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67e0308c7c0b4c349882b37daaac2f4f",
      "placeholder": "​",
      "style": "IPY_MODEL_c98d5053c2ed44a5b77fca9b11a44f8d",
      "value": " 83.3M/83.3M [43:31&lt;00:00, 33.4kB/s]"
     }
    },
    "67e0308c7c0b4c349882b37daaac2f4f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3e1f27f82b54742b7b5e5502be83328": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c98d5053c2ed44a5b77fca9b11a44f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1bc6a4df460400891cec8fbb840e9ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
